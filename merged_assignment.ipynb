{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1><center>Code NLP<center></h1>",
   "id": "a8308baecaeb9dbf"
  },
  {
   "cell_type": "markdown",
   "id": "a99feb2dcc02b174",
   "metadata": {},
   "source": "##### Imports:"
  },
  {
   "cell_type": "code",
   "id": "6c19efc5",
   "metadata": {},
   "source": [
    "# Standard library imports\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from typing import List, Set\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Gensim imports\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    adjusted_rand_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    f1_score,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    silhouette_score\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.manifold import trustworthiness\n",
    "\n",
    "# Transformers and datasets imports\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TextClassificationPipeline,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "# Other ML/DL imports\n",
    "import tensorflow_hub as hub\n",
    "from umap.umap_ import UMAP\n",
    "import hdbscan\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8fc49ee77f076d1",
   "metadata": {},
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2914fcec2c472a77",
   "metadata": {},
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9848d7b22a510f50",
   "metadata": {},
   "source": [
    "##### Import Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "id": "49e7e71a",
   "metadata": {},
   "source": [
    "# Import Data Frames\n",
    "with open ('0_data/statements.csv', 'r') as f:\n",
    "    generated = pd.read_csv(f)\n",
    "\n",
    "with open ('0_data/final_labeled_dataset.csv', 'r') as f:\n",
    "    parliament = pd.read_csv(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af135910553806d2",
   "metadata": {},
   "source": [
    "generated.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4106757ab6ccadd7",
   "metadata": {},
   "source": [
    "parliament.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bee0388181fb98b9",
   "metadata": {},
   "source": [
    "generated.statement.sample(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c830ed1da4157f6",
   "metadata": {},
   "source": [
    "parliament.translated_text.sample(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3661480ad641a85",
   "metadata": {},
   "source": [
    "generated.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12951166408420d5",
   "metadata": {},
   "source": [
    "parliament.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ced19dba9551230",
   "metadata": {},
   "source": [
    "##### Preprocessing Class:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac2f9f25b1666094",
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class Preprocess:\n",
    "    \"\"\"\n",
    "    Handles text preprocessing tasks including removal of stopwords, lemmatization,\n",
    "    and generation of trigrams. The class is designed to streamline the preparation\n",
    "    of textual data for further natural language processing tasks.\n",
    "\n",
    "    It includes utilities for basic text cleaning (removal of non-alphabetical\n",
    "    characters), tokenization, filtering of stopwords, lemmatization, and creating\n",
    "    trigram representations. The class requires nltk and its necessary resources\n",
    "    such as stopwords and the WordNet lemmatizer.\n",
    "\n",
    "    :ivar _stopwords: Set of stopwords used to filter out common words that do not\n",
    "                      contribute to the meaning of the text.\n",
    "    :type _stopwords: Set[str]\n",
    "    :ivar _lemmatizer: Instance of WordNetLemmatizer used for lemmatizing words\n",
    "                       to their base forms.\n",
    "    :type _lemmatizer: WordNetLemmatizer\n",
    "    \"\"\"\n",
    "    _stopwords: Set[str] = None\n",
    "    _lemmatizer: WordNetLemmatizer = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self._lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def rm_stopwords(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Removes stopwords from the given text.\n",
    "\n",
    "        This method processes the input text and removes all words found in the\n",
    "        internal stopwords list, returning the cleaned text.\n",
    "\n",
    "        :param text: The input text to process and remove stopwords from.\n",
    "        :type text: str\n",
    "        :return: The text with all stopwords removed.\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        return ' '.join([word for word in text.split()\n",
    "                         if word not in self._stopwords])\n",
    "\n",
    "    def lemmatize_doc(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Lemmatizes a document by processing each token.\n",
    "\n",
    "        This method takes a list of tokens (words), filters out non-alphabetic tokens,\n",
    "        stopwords, and words with a length of 2 or less. The remaining tokens are\n",
    "        lemmatized using the internal lemmatizer.\n",
    "\n",
    "        :param tokens: A list of word tokens to be lemmatized\n",
    "        :type tokens: List[str]\n",
    "        :return: A list of lemmatized tokens meeting the filtering criteria\n",
    "        :rtype: List[str]\n",
    "        \"\"\"\n",
    "        return [self._lemmatizer.lemmatize(word) for word in tokens\n",
    "                if word.isalpha() and word.lower() not in self._stopwords and len(word) > 2]\n",
    "\n",
    "    def trigrams(self, text: str) -> List[tuple]:\n",
    "        \"\"\"\n",
    "        Generate trigrams from the given text by tokenizing it into words and creating\n",
    "        groups of three consecutive tokens.\n",
    "\n",
    "        :param text: String input representing the text to process.\n",
    "        :return: A list of tuples where each tuple contains a trigram, i.e., three\n",
    "                 consecutive tokens from the provided text.\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize_doc(text)\n",
    "        return list(ngrams(tokens, 3))\n",
    "\n",
    "    @staticmethod\n",
    "    def basic_clean(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Cleans a given text by removing all non-alphabetical characters and converting it to lowercase.\n",
    "\n",
    "        This method processes a given text, removes all non-alphabetic characters, and ensures\n",
    "        the resulting text is in lowercase. It returns the cleaned-up version of the string.\n",
    "\n",
    "        :param text: The input text to be cleaned.\n",
    "        :type text: str\n",
    "        :return: A cleaned version of the input text, containing only lowercase alphabetic\n",
    "            characters and spaces.\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        return re.sub(r'[^a-z\\s]', '', str(text).lower())\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_doc(text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Tokenizes a given text into lowercase words. This method processes the input text by first converting\n",
    "        all characters to lowercase and then splitting the text into individual tokens (words). It is a simple\n",
    "        and effective way to prepare text for natural language processing tasks, enabling consistent analysis\n",
    "        by normalizing letter cases.\n",
    "\n",
    "        :param text: The input string to be tokenized. It represents a document or text fragment that needs\n",
    "            processing.\n",
    "        :type text: str\n",
    "        :return: A list of lowercase word tokens extracted from the input text.\n",
    "        :rtype: List[str]\n",
    "        \"\"\"\n",
    "        return word_tokenize(text.lower())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15b4ac25097ba2c",
   "metadata": {},
   "source": [
    "# initialize the preprocess class\n",
    "preprocessor = Preprocess()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2a5842e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdce88466c2dbb7",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa539ecd319d4cad",
   "metadata": {},
   "source": [
    "# set seed variable\n",
    "SEED = 42"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e37a26dd7289ca68",
   "metadata": {},
   "source": [
    "def tune_umap_parameters(embeddings, n_calls: int=50, verbose: bool=False):\n",
    "    \"\"\"\n",
    "    Tunes the parameters of UMAP to optimize the trustworthiness score of the dimensionality\n",
    "    reduction performed on a given embedding. This function uses the Scikit-Optimize\n",
    "    `gp_minimize` function to optimize `n_neighbors`, `min_dist`, and `metric` parameters\n",
    "    of UMAP over a specified number of calls. It returns the best parameter set and a\n",
    "    configured UMAP reducer object initialized with these parameters.\n",
    "\n",
    "    :param embeddings: The data to which dimensionality reduction is applied. It is expected\n",
    "        to be a multidimensional array-like structure.\n",
    "    :type embeddings: array-like of shape (n_samples, n_features)\n",
    "    :param n_calls: The number of optimization iterations to run while searching for the\n",
    "        optimal set of UMAP parameters. Defaults to 50.\n",
    "    :type n_calls: int\n",
    "    :param verbose: Indicates whether verbose output should be enabled during optimization\n",
    "        iterations. Defaults to False.\n",
    "    :type verbose: bool\n",
    "    :return: A tuple containing the best parameters found and a configured UMAP reducer\n",
    "        object. The reducer is initialized using the best found parameters.\n",
    "    :rtype: Tuple[Dict[str, Any], UMAP]\n",
    "    \"\"\"\n",
    "    space = [\n",
    "        Integer(10, 50, name='n_neighbors'),\n",
    "        Real(0.0, 0.3, name='min_dist'),\n",
    "        Categorical(['euclidean'], name='metric')\n",
    "    ]\n",
    "\n",
    "    def objective(params, embeddings, n_components=2):\n",
    "        n_neighbors, min_dist, metric = params\n",
    "\n",
    "        reducer = UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            metric=metric,\n",
    "            n_components=n_components,\n",
    "            random_state=SEED\n",
    "        )\n",
    "\n",
    "        embedding = reducer.fit_transform(embeddings)\n",
    "\n",
    "        trust_score = trustworthiness(\n",
    "            embeddings,\n",
    "            embedding,\n",
    "            n_neighbors=min(20, len(embeddings) - 1)\n",
    "        )\n",
    "\n",
    "        return -trust_score\n",
    "\n",
    "    result = gp_minimize(\n",
    "        lambda params: objective(params, embeddings),\n",
    "        space,\n",
    "        n_calls=n_calls,\n",
    "        random_state=SEED,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    best_params = {\n",
    "        'n_neighbors': result.x[0],\n",
    "        'min_dist': result.x[1],\n",
    "        'metric': result.x[2]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBest parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest score: {-result.fun:.4f}\")\n",
    "\n",
    "    best_reducer = UMAP(\n",
    "        **best_params,\n",
    "        n_components=2,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    return best_params, best_reducer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b43753dadc92cb78",
   "metadata": {},
   "source": [
    "def tune_hdbscan_parameters(embeddings,  n_calls: int=50, verbose: bool=False):\n",
    "    \"\"\"\n",
    "    Tunes HDBSCAN hyperparameters using the Bayesian optimization framework.\n",
    "\n",
    "    This function optimizes the hyperparameters for the HDBSCAN clustering algorithm\n",
    "    to maximize cluster quality, stability, and minimize noise ratio. The optimization\n",
    "    is carried out using a Gaussian process-based minimizer, `gp_minimize`. It returns\n",
    "    the best set of hyperparameters and the trained HDBSCAN clusterer.\n",
    "\n",
    "    :param embeddings: The data to be clustered. It should be a 2D array-like structure where\n",
    "        rows represent individual samples and columns represent features.\n",
    "    :type embeddings: numpy.ndarray or list of lists\n",
    "    :param n_calls: The number of calls to the optimization algorithm, specifying how many\n",
    "        sets of parameters will be evaluated. Defaults to 50.\n",
    "    :type n_calls: int\n",
    "    :param verbose: Whether to print intermediate results during the optimization process.\n",
    "        Defaults to False.\n",
    "    :type verbose: bool\n",
    "    :return: A tuple containing the best hyperparameters as a dictionary and a trained\n",
    "        HDBSCAN instance with those parameters.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    space = [\n",
    "        Integer(3, 15, name='min_cluster_size'),\n",
    "        Integer(3, 10, name='min_samples'),\n",
    "        Real(0.0, 0.5, name='cluster_selection_epsilon'),\n",
    "        Categorical(['euclidean'], name='metric')\n",
    "    ]\n",
    "\n",
    "    def objective(params, embeddings, n_runs=5):\n",
    "        min_cluster_size, min_samples, cluster_selection_epsilon, metric = params\n",
    "\n",
    "        cluster_results = []\n",
    "        silhouette_scores = []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            clusterer = hdbscan.HDBSCAN(\n",
    "                min_cluster_size=min_cluster_size,\n",
    "                min_samples=min_samples,\n",
    "                cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "                metric=metric\n",
    "            )\n",
    "\n",
    "            labels = clusterer.fit_predict(embeddings)\n",
    "            cluster_results.append(labels)\n",
    "\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            if n_clusters > 1:\n",
    "                mask = labels != -1\n",
    "                if np.sum(mask) > 1:\n",
    "                    sil_score = silhouette_score(embeddings[mask], labels[mask])\n",
    "                    silhouette_scores.append(sil_score)\n",
    "\n",
    "        stability_scores = []\n",
    "        for i in range(len(cluster_results)):\n",
    "            for j in range(i + 1, len(cluster_results)):\n",
    "                ari = adjusted_rand_score(cluster_results[i], cluster_results[j])\n",
    "                stability_scores.append(ari)\n",
    "\n",
    "        mean_stability = np.mean(stability_scores) if stability_scores else 0\n",
    "        mean_silhouette = np.mean(silhouette_scores) if silhouette_scores else 0\n",
    "\n",
    "        noise_ratio = np.sum(cluster_results[-1] == -1) / len(cluster_results[-1])\n",
    "\n",
    "        composite_score = (0.4 * mean_stability +\n",
    "                          0.4 * mean_silhouette -\n",
    "                          0.2 * noise_ratio)\n",
    "\n",
    "        return -composite_score\n",
    "\n",
    "    result = gp_minimize(\n",
    "        lambda params: objective(params, embeddings),\n",
    "        space,\n",
    "        n_calls=n_calls,\n",
    "        random_state=SEED,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    best_params = {\n",
    "        'min_cluster_size': result.x[0],\n",
    "        'min_samples': result.x[1],\n",
    "        'cluster_selection_epsilon': result.x[2],\n",
    "        'metric': result.x[3]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBest HDBSCAN parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest score: {-result.fun:.4f}\")\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(**best_params)\n",
    "    labels = clusterer.fit_predict(embeddings)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    noise_points = sum(1 for label in labels if label == -1)\n",
    "\n",
    "    print(f\"\\nNumber of clusters: {n_clusters}\")\n",
    "    print(f\"Number of noise points: {noise_points} ({noise_points/len(labels):.2%})\")\n",
    "\n",
    "    return best_params, clusterer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69bb2f1b31bc8b2f",
   "metadata": {},
   "source": [
    "def get_closest_words(topic_vector, word_vectors, n=10):\n",
    "    \"\"\"\n",
    "    Get the indices of the top `n` closest words to the given topic vector.\n",
    "\n",
    "    This function calculates cosine similarities between a topic vector and a\n",
    "    set of word vectors. It then identifies the top `n` indices of the word vectors\n",
    "    that are most similar to the topic vector.\n",
    "\n",
    "    :param topic_vector: A 1D numerical array representing the topic vector.\n",
    "    :param word_vectors: A 2D numerical array where each row corresponds to a\n",
    "        word vector.\n",
    "    :param n: An integer representing the number of closest words to retrieve.\n",
    "        Defaults to 10.\n",
    "    :return: A 1D numpy array containing the indices of the top `n` closest\n",
    "        word vectors in descending order of similarity.\n",
    "    \"\"\"\n",
    "    similarities = cosine_similarity([topic_vector], word_vectors)[0]\n",
    "    return np.argsort(similarities)[-n:][::-1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7b13c187991c369",
   "metadata": {},
   "source": [
    "def tm_cleaning(doc):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses a given document for text mining purposes.\n",
    "\n",
    "    This function processes a text document through several steps: basic cleaning,\n",
    "    tokenization, and lemmatization. These steps prepare the textual content for\n",
    "    further analysis or machine learning tasks by transforming it into a format\n",
    "    suitable for natural language processing.\n",
    "\n",
    "    :param doc: The text document to be cleaned and preprocessed.\n",
    "    :type doc: str\n",
    "\n",
    "    :return: A list of lemmatized tokens from the cleaned document.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    doc = preprocessor.basic_clean(doc)\n",
    "    tokens = preprocessor.tokenize_doc(doc)\n",
    "    tokens = preprocessor.lemmatize_doc(tokens)\n",
    "    return tokens"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69aac03b50bcfb1",
   "metadata": {},
   "source": [
    "# group generated df\n",
    "df_chatgpt = generated[generated.provider == 'chatgpt']\n",
    "df_deepseek = generated[generated.provider == 'deepseek']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1559c5953063997c",
   "metadata": {},
   "source": [
    "# create document vectors for topic modeling analysis\n",
    "docs_chatgpt = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_chatgpt.statement.apply(tm_cleaning).tolist())]\n",
    "docs_deepseek = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_deepseek.statement.apply(tm_cleaning).tolist())]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5eb87db10397a1b",
   "metadata": {},
   "source": [
    "# convert the previously created objects back into plain text strings\n",
    "texts_chatgpt = [' '.join(doc.words) if hasattr(doc, 'words') else doc for doc in docs_chatgpt]\n",
    "texts_deepseek = [' '.join(doc.words) if hasattr(doc, 'words') else doc for doc in docs_deepseek]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6aad11c7d24a9e3",
   "metadata": {},
   "source": [
    "# create and normalize sentence embeddings\n",
    "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "scaler = StandardScaler()\n",
    "embeddings_chatgpt = scaler.fit_transform(embed(texts_chatgpt).numpy())\n",
    "embeddings_deepseek = scaler.fit_transform(embed(texts_deepseek).numpy())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23bab445a3489579",
   "metadata": {},
   "source": [
    "# tune umap params gpt\n",
    "best_umap_params_chatgpt, reducer_chatgpt = tune_umap_parameters(embeddings_chatgpt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "95aad10e205ff94a",
   "metadata": {},
   "source": [
    "# tune umap params deepseek\n",
    "best_umap_params_deepseek, reducer_deepseek = tune_umap_parameters(embeddings_deepseek)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c35a0143c2754942",
   "metadata": {},
   "source": [
    "# tune hdbscan params gpt\n",
    "best_hdbscan_params_chatgpt, clusterer_chatgpt = tune_hdbscan_parameters(embeddings_chatgpt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "228733594a791ca2",
   "metadata": {},
   "source": [
    "# tune hdbscan params deepseek\n",
    "best_hdbscan_params_deepseek, clusterer_deepseek = tune_hdbscan_parameters(embeddings_deepseek)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0b2bfde05229314",
   "metadata": {},
   "source": [
    "# fit transform umap embeddings\n",
    "umap_embeddings_chatgpt = reducer_chatgpt.fit_transform(embeddings_chatgpt)\n",
    "umap_embeddings_deepseek = reducer_deepseek.fit_transform(embeddings_deepseek)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e8d96b52e38b2fb",
   "metadata": {},
   "source": [
    "# fit hdbscan clusters\n",
    "cluster_labels_chatgpt = clusterer_chatgpt.fit_predict(umap_embeddings_chatgpt)\n",
    "cluster_labels_deepseek = clusterer_deepseek.fit_predict(umap_embeddings_deepseek)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d48f6843a012f59f",
   "metadata": {},
   "source": [
    "# store results in dictionary\n",
    "umap_hdbscan_results = {\n",
    "    'ChatGPT': (umap_embeddings_chatgpt, cluster_labels_chatgpt),\n",
    "    'DeepSeek': (umap_embeddings_deepseek, cluster_labels_deepseek)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85f32a8d191bd918",
   "metadata": {},
   "source": [
    "# plot reduced document clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "fig.suptitle('Document Clusters Comparison', fontsize=16, y=1.05)\n",
    "\n",
    "for idx, (name, res) in enumerate(umap_hdbscan_results.items()):\n",
    "    scatter = axes[idx].scatter(res[0][:, 0],\n",
    "                               res[0][:, 1],\n",
    "                               c=res[1],\n",
    "                               cmap='Spectral',\n",
    "                               alpha=0.6)\n",
    "    fig.colorbar(scatter, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{name}')\n",
    "    axes[idx].set_xlabel('UMAP 1')\n",
    "    axes[idx].set_ylabel('UMAP 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29a24917c082921b",
   "metadata": {},
   "source": [
    "# calculates topic vectors from the clustered gpt documents\n",
    "n_clusters_chatgpt = len(np.unique(cluster_labels_chatgpt[cluster_labels_chatgpt != -1]))\n",
    "\n",
    "topic_vectors = []\n",
    "\n",
    "for i in range(n_clusters_chatgpt):\n",
    "    cluster_docs = embeddings_chatgpt[cluster_labels_chatgpt == i]\n",
    "    centroid = np.mean(cluster_docs, axis=0)\n",
    "    topic_vectors.append(centroid)\n",
    "\n",
    "topic_vectors_chatgpt = np.array(topic_vectors)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "daad045f916c1a96",
   "metadata": {},
   "source": [
    "# calculates topic vectors from the clustered deepseek documents\n",
    "n_clusters_deepseek = len(np.unique(cluster_labels_deepseek[cluster_labels_deepseek != -1]))\n",
    "\n",
    "topic_vectors = []\n",
    "\n",
    "for i in range(n_clusters_deepseek):\n",
    "    cluster_docs = embeddings_deepseek[cluster_labels_deepseek == i]\n",
    "    centroid = np.mean(cluster_docs, axis=0)\n",
    "    topic_vectors.append(centroid)\n",
    "\n",
    "topic_vectors_deepseek = np.array(topic_vectors)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b3e6bb3db26d0488",
   "metadata": {},
   "source": [
    "##### Results:"
   ]
  },
  {
   "cell_type": "code",
   "id": "796aee010833b20a",
   "metadata": {},
   "source": [
    "def top_words(cluster_labels,\n",
    "              texts,\n",
    "              topic_vectors,\n",
    "              embeddings,\n",
    "              n_words=10):\n",
    "    \"\"\"\n",
    "    Retrieves the top words from each cluster topic based on a calculated TF-IDF\n",
    "    matrix. The analysis is performed by grouping documents according to their\n",
    "    associated cluster labels, then identifying the top words within each cluster\n",
    "    using their significance scores.\n",
    "\n",
    "    :param cluster_labels: Cluster labels assigned to each document, where -1\n",
    "        indicates noise and other integers correspond to specific clusters.\n",
    "    :type cluster_labels: numpy.ndarray\n",
    "    :param texts: List of documents (strings) from which clusters and word\n",
    "        frequencies are extracted.\n",
    "    :type texts: list\n",
    "    :param topic_vectors: Feature vectors associated with the topics, describing\n",
    "        underlying dimensions of the clusters.\n",
    "    :type topic_vectors: numpy.ndarray\n",
    "    :param embeddings: Precomputed vector embeddings for documents or words,\n",
    "        enhancing semantic representation of the data.\n",
    "    :type embeddings: numpy.ndarray\n",
    "    :param n_words: Number of top words to retrieve for each cluster topic.\n",
    "        Defaults to 10 if not specified.\n",
    "    :type n_words: int\n",
    "\n",
    "    :return: A list containing the top words across all clusters, flattened into a\n",
    "        single collection from nested topics.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    n_clusters = len(np.unique(cluster_labels[cluster_labels != -1]))\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    doc_term_matrix = count_vectorizer.fit_transform(texts)\n",
    "    vocabulary = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "    c_tf_idf_matrix = np.zeros((n_clusters, len(vocabulary)))\n",
    "\n",
    "    for cluster_id in range(n_clusters):\n",
    "\n",
    "        cluster_docs = doc_term_matrix[cluster_labels == cluster_id]\n",
    "\n",
    "        if cluster_docs.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        cluster_tf = np.array(cluster_docs.sum(axis=0).flatten())[0]\n",
    "        total_docs = len(texts)\n",
    "        cluster_size = cluster_docs.shape[0]\n",
    "\n",
    "        tf_idf = cluster_tf * np.log1p(total_docs / (cluster_size + 1))\n",
    "        c_tf_idf_matrix[cluster_id] = tf_idf\n",
    "\n",
    "    all_top_words = []\n",
    "\n",
    "    for topic_idx in range(c_tf_idf_matrix.shape[0]):\n",
    "        top_n_idx = c_tf_idf_matrix[topic_idx].argsort()[-n_words:][::-1]\n",
    "        top_words = [vocabulary[idx] for idx in top_n_idx]\n",
    "        all_top_words.append(top_words)\n",
    "\n",
    "        print(f\"\\nTopic {topic_idx + 1} Top Words:\")\n",
    "        print(\", \".join(top_words))\n",
    "\n",
    "    return [item for sublist in all_top_words for item in sublist]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "806a8b57d8285ba7",
   "metadata": {},
   "source": [
    "top_words_chatgpt = top_words(cluster_labels_chatgpt,\n",
    "                              texts_chatgpt,\n",
    "                              topic_vectors_chatgpt,\n",
    "                              embeddings_chatgpt,\n",
    "                              n_words=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e088c06c187ef73e",
   "metadata": {},
   "source": [
    "top_words_deepseek = top_words(cluster_labels_deepseek,\n",
    "                               texts_deepseek,\n",
    "                               topic_vectors_deepseek,\n",
    "                               embeddings_deepseek,\n",
    "                               n_words=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72e7349b9584b53f",
   "metadata": {},
   "source": [
    "unique_words_chatgpt = set(top_words_chatgpt) - set(top_words_deepseek)\n",
    "print(f'Unique words in ChatGPT: {unique_words_chatgpt}')\n",
    "\n",
    "unique_words_deepseek = set(top_words_deepseek) - set(top_words_chatgpt)\n",
    "print(f'Unique words deepseek: {unique_words_deepseek}')\n",
    "\n",
    "common_words = set(top_words_deepseek) & set(top_words_chatgpt)\n",
    "print(f'Common words: {common_words}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47c23e944b92d395",
   "metadata": {},
   "source": [
    "def evaluate_topic_modeling(cluster_labels, embeddings, texts, topic_vectors, model_results=None):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a topic modeling algorithm using various clustering,\n",
    "    coherence, distinctiveness, and topic size metrics.\n",
    "\n",
    "    The function computes clustering metrics such as silhouette score, calinski-harabasz\n",
    "    score, and davies-bouldin score for all valid cluster labels. It also generates top\n",
    "    terms for each topic cluster and computes coherence metrics using these terms. Additionally,\n",
    "    distinctiveness of topic vectors is evaluated using cosine similarity and topic size\n",
    "    metrics such as standard deviation, range, and noise ratio are calculated.\n",
    "\n",
    "    :param cluster_labels: An array or list of cluster labels assigned to each data point.\n",
    "        Cluster labels of -1 indicate outliers or noise.\n",
    "    :type cluster_labels: array-like of shape (n_samples,)\n",
    "    :param embeddings: The embeddings or high-dimensional representations of the data points\n",
    "        used for clustering.\n",
    "    :type embeddings: array-like of shape (n_samples, n_features)\n",
    "    :param texts: The original documents or texts associated with each data point.\n",
    "    :type texts: list of str\n",
    "    :param topic_vectors: A matrix where each row represents the vectorized representation\n",
    "        of a topic.\n",
    "    :type topic_vectors: array-like of shape (n_topics, n_features)\n",
    "    :param model_results: Optional dictionary containing precomputed model outputs or\n",
    "        intermediate results, such as cluster information or existing metrics.\n",
    "    :type model_results: dict, optional\n",
    "    :return: A dictionary containing various evaluation metrics categorized into\n",
    "        clustering metrics, coherence, distinctiveness, and size metrics.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    valid_mask = cluster_labels != -1\n",
    "    clustering_metrics = {}\n",
    "\n",
    "    if np.sum(valid_mask) > 1:\n",
    "        clustering_metrics = {\n",
    "            'silhouette_score': silhouette_score(\n",
    "                embeddings[valid_mask],\n",
    "                cluster_labels[valid_mask]\n",
    "            ),\n",
    "            'calinski_harabasz_score': calinski_harabasz_score(\n",
    "                embeddings[valid_mask],\n",
    "                cluster_labels[valid_mask]\n",
    "            ),\n",
    "            'davies_bouldin_score': davies_bouldin_score(\n",
    "                embeddings[valid_mask],\n",
    "                cluster_labels[valid_mask]\n",
    "            )\n",
    "        }\n",
    "\n",
    "    tokenized_texts = [text.split() for text in texts]\n",
    "    dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "    topic_words = []\n",
    "    for i in range(len(topic_vectors)):\n",
    "        topic_mask = cluster_labels == i\n",
    "        topic_texts = [text for text, mask in zip(texts, topic_mask) if mask]\n",
    "        words = ' '.join(topic_texts).split()\n",
    "        word_freq = {}\n",
    "        for word in words:\n",
    "            word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        topic_words.append([word for word, freq in sorted_words[:10]])  # top 10 words\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "\n",
    "    coherence_metrics = {\n",
    "        'c_v_coherence': coherence_model.get_coherence()\n",
    "    }\n",
    "\n",
    "    topic_similarities = cosine_similarity(topic_vectors)\n",
    "    np.fill_diagonal(topic_similarities, 0)\n",
    "    distinctiveness_metrics = {\n",
    "        'mean_similarity': np.mean(topic_similarities),\n",
    "        'max_similarity': np.max(topic_similarities)\n",
    "    }\n",
    "\n",
    "    topic_sizes = np.bincount(cluster_labels[cluster_labels != -1])\n",
    "    size_metrics = {\n",
    "        'size_std': np.std(topic_sizes),\n",
    "        'size_range': np.ptp(topic_sizes),\n",
    "        'noise_ratio': np.sum(cluster_labels == -1) / len(cluster_labels)\n",
    "    }\n",
    "\n",
    "    evaluation_results = {\n",
    "        'clustering_metrics': clustering_metrics,\n",
    "        'coherence': coherence_metrics,\n",
    "        'distinctiveness': distinctiveness_metrics,\n",
    "        'size_metrics': size_metrics\n",
    "    }\n",
    "\n",
    "    print(\"\\nEvaluation Results\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for category, metrics in evaluation_results.items():\n",
    "        print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "    return evaluation_results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83a121039dbe3708",
   "metadata": {},
   "source": [
    "eval_res_chatgpt = evaluate_topic_modeling(cluster_labels_chatgpt,\n",
    "                                            embeddings_chatgpt,\n",
    "                                            texts_chatgpt,\n",
    "                                            topic_vectors_chatgpt,\n",
    "                                            model_results=umap_hdbscan_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a982a773608c171",
   "metadata": {},
   "source": [
    "eval_res_deepseek = evaluate_topic_modeling(cluster_labels_deepseek,\n",
    "                                            embeddings_deepseek,\n",
    "                                            texts_deepseek,\n",
    "                                            topic_vectors_deepseek,\n",
    "                                            model_results=umap_hdbscan_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bb2b291f5d6aa0bd",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3081716f",
   "metadata": {},
   "source": "##### VADER:"
  },
  {
   "cell_type": "code",
   "id": "1f526259b909bec5",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of the given text and returns the compound sentiment score.\n",
    "\n",
    "    The function utilizes a sentiment intensity analyzer to evaluate the sentiment\n",
    "    polarity of the input text. It calculates and returns the compound score, which\n",
    "    is a numerical measure of sentiment ranging from -1 (most negative) to 1\n",
    "    (most positive).\n",
    "\n",
    "    :param text: The input text for which the sentiment needs to be analyzed.\n",
    "    :type text: str\n",
    "    :return: The compound sentiment score of the analyzed text.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c45008254b56af2",
   "metadata": {},
   "source": [
    "# apply model\n",
    "parliament['sentiment_vader'] = parliament['translated_text'].apply(get_sentiment)\n",
    "generated['sentiment_vader'] = generated['statement'].apply(get_sentiment)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25bf48b4b0b08d8b",
   "metadata": {},
   "source": "###### Results:"
  },
  {
   "cell_type": "code",
   "id": "8c18ae029e66af17",
   "metadata": {},
   "source": [
    "def get_descriptives(sentiment):\n",
    "    \"\"\"\n",
    "    Compute and return descriptive statistics for the given sentiment data.\n",
    "\n",
    "    This function calculates and returns the mean, standard deviation, minimum,\n",
    "    maximum, and count of the provided sentiment data.\n",
    "\n",
    "    :param sentiment: A Pandas Series or iterable containing sentiment data\n",
    "                      for which descriptive statistics will be calculated.\n",
    "    :type sentiment: pandas.Series | list | iterable\n",
    "    :return: A list containing the mean, standard deviation, minimum,\n",
    "             maximum, and count of the sentiment data, in that order.\n",
    "    :rtype: list[float | int]\n",
    "    \"\"\"\n",
    "    return [sentiment.mean(), sentiment.std(), sentiment.min(), sentiment.max(), sentiment.count()]\n",
    "\n",
    "sentiment_vader_parliament = get_descriptives(parliament['sentiment_vader'])\n",
    "is_openai = generated['provider'] == 'chatgpt'\n",
    "is_deepseek = generated['provider'] == 'deepseek'\n",
    "sentiment_vader_deepseek = get_descriptives(generated[is_deepseek]['sentiment_vader'])\n",
    "sentiment_vader_chatgpt = get_descriptives(generated[is_openai]['sentiment_vader'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2cbd05796059bbd",
   "metadata": {},
   "source": [
    "# Create table\n",
    "sentiment_table = PrettyTable()\n",
    "sentiment_table.field_names = ['Source', 'Mean', 'Std Dev', 'Min', 'Max', 'Count']\n",
    "sentiment_table.add_row(['Original', *sentiment_vader_parliament])\n",
    "sentiment_table.add_row(['ChatGPT', *sentiment_vader_chatgpt])\n",
    "sentiment_table.add_row(['DeepSeek', *sentiment_vader_deepseek])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "136b6fc3d8af60d1",
   "metadata": {},
   "source": [
    "# Print table\n",
    "print('Sentiment Analysis (Vader) Results:')\n",
    "print('> uncleaned data')\n",
    "print(sentiment_table)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7005cf2",
   "metadata": {},
   "source": "##### RoBERTa (parlasent):"
  },
  {
   "cell_type": "code",
   "id": "de73056d",
   "metadata": {},
   "source": [
    "sentiment_analyzer = \"classla/xlm-r-parlasent\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(sentiment_analyzer)\n",
    "def get_token_count(text):\n",
    "    tokens = tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
    "    return len(tokens)\n",
    "\n",
    "parliament['token_count'] = parliament['translated_text'].apply(get_token_count) # âœ… should run checked with df.info()\n",
    "parliament['token_count'].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad0c8435",
   "metadata": {},
   "source": [
    "# Calculate how many texts exceed the token limit (512 tokens)\n",
    "# Only relevant for the parliament dataset as the generated dataset is capped at 400 tokens per piece\n",
    "over_limit_count = (parliament['token_count'] > 512).sum()\n",
    "print(f\"Number of texts exceeding 512 tokens: {over_limit_count} out of {len(parliament)} ({over_limit_count/len(generated)*100:.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69bb6abd",
   "metadata": {},
   "source": [
    "# Initialize the model components\n",
    "sentiment_analyzer = \"classla/xlm-r-parlasent\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(sentiment_analyzer)\n",
    "config = AutoConfig.from_pretrained(sentiment_analyzer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(sentiment_analyzer)\n",
    "\n",
    "# Sweet piece of code to set the device to use hardware acceleration\n",
    "if torch.cuda.is_available():\n",
    "    device = 0 # CUDA\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps' # Apple Silicon\n",
    "else:\n",
    "    device = -1 # CPU\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Using only the last 510 tokens of the text for sentiment analysis\n",
    "def top_token(text):\n",
    "    tokens = tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
    "    last_tokens = tokens[-510:]  # Truncate to last 510\n",
    "    input_ids = tokenizer.build_inputs_with_special_tokens(last_tokens)\n",
    "    return tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "# Create the pipeline with automatic device detection\n",
    "sentiment_analysis = TextClassificationPipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    return_all_scores=True,\n",
    "    task='sentiment_analysis', \n",
    "    device=device,\n",
    "    function_to_apply=\"none\"\n",
    ")\n",
    "\n",
    "# Apply sentiment analysis\n",
    "generated['sentiment_bert'] = generated['statement'].apply(lambda x: sentiment_analysis(top_token(x))[0])\n",
    "print('finished sentiment prediction for generated statements')\n",
    "\n",
    "parliament['sentiment_bert'] = parliament['translated_text'].apply(lambda x: sentiment_analysis(top_token(x))[0])\n",
    "print('finished sentiment prediction for original statements')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "09c1d7d9",
   "metadata": {},
   "source": [
    "def extract_sentiment_parts(sentiment_data):\n",
    "    # Extract the first element from the list if it's a list\n",
    "    if isinstance(sentiment_data, list):\n",
    "        sentiment_data = sentiment_data[0]\n",
    "        \n",
    "    # Extract label and score\n",
    "    label = sentiment_data.get('label', '')\n",
    "    score = sentiment_data.get('score', 0.0)\n",
    "    \n",
    "    return label, score\n",
    "\n",
    "# Apply the function to create new columns\n",
    "generated['sentiment_bert_label'] = generated['sentiment_bert'].apply(lambda x: extract_sentiment_parts(x)[0])\n",
    "generated['sentiment_bert_score'] = generated['sentiment_bert'].apply(lambda x: extract_sentiment_parts(x)[1])\n",
    "\n",
    "parliament['sentiment_bert_label'] = parliament['sentiment_bert'].apply(lambda x: extract_sentiment_parts(x)[0])\n",
    "parliament['sentiment_bert_score'] = parliament['sentiment_bert'].apply(lambda x: extract_sentiment_parts(x)[1])\n",
    "\n",
    "# Display a sample of the results\n",
    "print(\"Generated data sample:\")\n",
    "print(generated[['sentiment_bert_label', 'sentiment_bert_score']].head())\n",
    "\n",
    "print(\"\\nOriginal data sample:\")\n",
    "print(parliament[['sentiment_bert_label', 'sentiment_bert_score']].head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "673d3236",
   "metadata": {},
   "source": "###### Results:"
  },
  {
   "cell_type": "code",
   "id": "2a5b6fe0",
   "metadata": {},
   "source": [
    "# funciton defined above\n",
    "sentiment_roberta_parliament = get_descriptives(parliament['sentiment_bert_score'])\n",
    "# boolean mask defined above\n",
    "sentiment_roberta_deepseek = get_descriptives(generated[is_deepseek]['sentiment_bert_score'])\n",
    "sentiment_roberta_chatgpt = get_descriptives(generated[is_openai]['sentiment_bert_score'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8d13829",
   "metadata": {},
   "source": [
    "# Create and format table\n",
    "sentiment_table = PrettyTable()\n",
    "sentiment_table.field_names = ['Source', 'Mean', 'Std Dev', 'Min', 'Max', 'Count']\n",
    "\n",
    "sentiment_table.add_row(['Original', *sentiment_roberta_parliament])\n",
    "sentiment_table.add_row(['ChatGPT', *sentiment_roberta_chatgpt])\n",
    "sentiment_table.add_row(['DeepSeek', *sentiment_roberta_deepseek])\n",
    "\n",
    "# Print table\n",
    "print('Sentiment Analysis Results:')\n",
    "print(sentiment_table)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8f8458be56eaaaf",
   "metadata": {},
   "source": [
    "### Extremity Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7756928fcb574",
   "metadata": {},
   "source": [
    "##### Ridge Regression:"
   ]
  },
  {
   "cell_type": "code",
   "id": "8485f127e80590c5",
   "metadata": {},
   "source": [
    "def reg_preprocess_text(dataset):\n",
    "    return dataset.map(\n",
    "        lambda x: ' '.join(\n",
    "            preprocessor.lemmatize_doc(\n",
    "                preprocessor.tokenize_doc(\n",
    "                    preprocessor.rm_stopwords(\n",
    "                        preprocessor.basic_clean(x)  # Remove ['translated_text'] access\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "X = parliament['translated_text']\n",
    "X = reg_preprocess_text(X)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "749857d92889254b",
   "metadata": {},
   "source": [
    "y = parliament['label']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a469ad71d418e7e",
   "metadata": {},
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f4b27c6cb72a87e",
   "metadata": {},
   "source": [
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a3222a9810b3f06a",
   "metadata": {},
   "source": [
    "# Train Ridge regression model\n",
    "model = Ridge()\n",
    "model.fit(X_train_vec, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de0992a01f80f608",
   "metadata": {},
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_test_vec)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Results:",
   "id": "1b1ded4364a470bc"
  },
  {
   "cell_type": "code",
   "id": "fb623a485ff305c3",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b65a90ce04603345",
   "metadata": {},
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.plot([-1, 1], [-1, 1], '--', color='gray')\n",
    "plt.title(\"Predicted vs. Actual Extremity\")\n",
    "plt.xlabel(\"Actual Extremity\")\n",
    "plt.ylabel(\"Predicted Extremity\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2150e0336eaed957",
   "metadata": {},
   "source": [
    "##### RoBERTa:"
   ]
  },
  {
   "cell_type": "code",
   "id": "86d5b9a881748e7d",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f17a47cf77564475",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "df = parliament[parliament[\"translated_text\"].notna() & parliament[\"label\"].notna()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e203fe2e6de8473",
   "metadata": {},
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85a145f9ecc37c86",
   "metadata": {},
   "source": [
    "# Prepare datasets\n",
    "train_df = train_df.rename(columns={\"label\": \"labels\"})\n",
    "test_df = test_df.rename(columns={\"label\": \"labels\"})\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"translated_text\", \"labels\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"translated_text\", \"labels\"]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "824ea6a7068d185d",
   "metadata": {},
   "source": [
    "# Use RoBERTa for regression\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6139fb00a1b0e73b",
   "metadata": {},
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"translated_text\"], padding=\"max_length\", truncation=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43d0a6507abd7edc",
   "metadata": {},
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b821725637da752d",
   "metadata": {},
   "source": [
    "# Load model for regression\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")\n",
    "model.config.hidden_dropout_prob = 0.3  # reduce overfitting"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "388eee1a053c5e19",
   "metadata": {},
   "source": [
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.squeeze()\n",
    "    return {\n",
    "        \"mse\": mean_squared_error(labels, preds),\n",
    "        \"r2\": r2_score(labels, preds)\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66366f26362583ce",
   "metadata": {},
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./spectrum_bert_results\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=12,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./spectrum_logs\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cd7867f99bb46fa",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e15c166a9b532ee4",
   "metadata": {},
   "source": [
    "# train\n",
    "trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Results:",
   "id": "903029784ad8020"
  },
  {
   "cell_type": "code",
   "id": "bd9094807a5d563",
   "metadata": {},
   "source": [
    "# evaluate\n",
    "trainer.evaluate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73412eb9c2bba82f",
   "metadata": {},
   "source": [
    "model.save_pretrained(\"roberta_best\")\n",
    "tokenizer.save_pretrained(\"roberta_best\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3496fdf3d9dfc8ac",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "statements = generated[\"statement\"].tolist()\n",
    "\n",
    "model_path = \"roberta_best\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "extremity_scores = []\n",
    "for text in statements:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        score = outputs.logits.item()\n",
    "        extremity_scores.append(score)\n",
    "\n",
    "generated[\"extremity_score\"] = extremity_scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a239791a0cab825",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(data=generated, x=\"extremity_score\", hue=\"provider\", fill=True, common_norm=False, alpha=0.5)\n",
    "plt.axvline(0, linestyle=\"--\", color=\"gray\")\n",
    "plt.title(\"Distribution of Predicted Extremity Scores by Provider\")\n",
    "plt.xlabel(\"Extremity Score (-1 = Left, +1 = Right)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e56b9b26c27d1451",
   "metadata": {},
   "source": [
    "sns.boxplot(data=generated, x=\"provider\", y=\"extremity_score\")\n",
    "plt.title(\"Extremity Score Distribution per LLM\")\n",
    "plt.axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "plt.ylabel(\"Predicted Extremity\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4be249b3713e2b4",
   "metadata": {},
   "source": [
    "print(generated.groupby(\"provider\")[\"extremity_score\"].agg([\"mean\", \"std\", \"min\", \"max\", \"median\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36f67b0ebf135e62",
   "metadata": {},
   "source": [
    "chatgpt_df = generated[generated[\"provider\"].str.lower() == \"chatgpt\"]\n",
    "num_left_leaning = (chatgpt_df[\"extremity_score\"] < 0).sum()\n",
    "total = len(chatgpt_df)\n",
    "print(f\"ChatGPT statements leaning left (< 0): {num_left_leaning} out of {total} ({(num_left_leaning/total)*100:.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
