{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b689e9be",
   "metadata": {},
   "source": [
    "- As we have to hand in one file for data, one file for our analysis and one file for our text, I would suggst to merge the entirety of the analysis into this wb. \n",
    "- maybe we can have the data generation in a seperate file. \n",
    "\n",
    "- I would also suggest putting all the code into functions that we can comment out the fn calls to not have to run the entire code over and over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991794c",
   "metadata": {},
   "source": [
    "### Importing Data Sets\n",
    "with open('../0_data/statements.csv', 'r') as file:\n",
    "\n",
    "    # headers = ['prompt', 'client', 'opt1', 'opt2', 'opt3', 'completion']\n",
    "    df_generated = pd.read_csv(file, index_col=False)\n",
    "    \n",
    "df_generated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bb1cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edf9062",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import seaborn as sns\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a603ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = pd.read_csv('/content/drive/MyDrive/NLP/eu_debate_transcripts_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb45c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm = pd.read_csv('/content/drive/MyDrive/NLP/statements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/content/drive/MyDrive/NLP/extremity_merged_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning with stopwords\n",
    "def clean_text_basic(text):\n",
    "    return re.sub(r'[^a-z\\s]', '', str(text).lower())\n",
    "\n",
    "df_real['clean_with_stopwords'] = df_real['translated_text'].apply(clean_text_basic)\n",
    "df_llm['clean_with_stopwords'] = df_llm['statement'].apply(clean_text_basic)\n",
    "df_train['clean_with_stopwords'] = df_train['translated_text'].apply(clean_text_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a818ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length + Style Metrics (with stopwords)\n",
    "df_real['char_count'] = df_real['clean_with_stopwords'].str.len()\n",
    "df_real['word_count'] = df_real['clean_with_stopwords'].str.split().str.len()\n",
    "df_real['source'] = 'Real'\n",
    "\n",
    "df_llm['char_count'] = df_llm['clean_with_stopwords'].str.len()\n",
    "df_llm['word_count'] = df_llm['clean_with_stopwords'].str.split().str.len()\n",
    "df_llm['source'] = df_llm['provider'].str.capitalize()\n",
    "\n",
    "df_train['char_count'] = df_train['clean_with_stopwords'].str.len()\n",
    "df_train['word_count'] = df_train['clean_with_stopwords'].str.split().str.len()\n",
    "df_train['source'] = 'Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning without stopwords\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df_real['clean_no_stopwords'] = df_real['clean_with_stopwords'].apply(remove_stopwords)\n",
    "df_llm['clean_no_stopwords'] = df_llm['clean_with_stopwords'].apply(remove_stopwords)\n",
    "df_train['clean_no_stopwords'] = df_train['clean_with_stopwords'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine for analysis\n",
    "df_eda = pd.concat([\n",
    "    df_real[['char_count', 'word_count', 'ttr', 'source']],\n",
    "    df_llm[['char_count', 'word_count', 'ttr', 'source']],\n",
    "    df_train[['char_count', 'word_count', 'ttr', 'source']]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequency analysis\n",
    "def get_word_counts(texts):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "        words.extend(tokens)\n",
    "    return Counter(words)\n",
    "\n",
    "real_words = get_word_counts(df_real['clean_no_stopwords'])\n",
    "llm_words = get_word_counts(df_llm['clean_no_stopwords'])\n",
    "train_words = get_word_counts(df_train['clean_no_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20\n",
    "real_top20 = pd.DataFrame(real_words.most_common(20), columns=['word', 'real_count'])\n",
    "llm_top20 = pd.DataFrame(llm_words.most_common(20), columns=['word', 'llm_count'])\n",
    "train_top20 = pd.DataFrame(train_words.most_common(20), columns=['word', 'train_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge top word frequencies\n",
    "word_counts = pd.merge(real_top20, llm_top20, on='word', how='outer').fillna(0)\n",
    "word_counts = pd.merge(word_counts, train_top20, on='word', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: Character Count\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(data=df_eda, x='char_count', hue='source', bins=40, element='step', stat='count', common_norm=False)\n",
    "plt.title(\"Character Count Distribution by Source\")\n",
    "plt.xlabel(\"Character Count\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8af500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot: Type-Token Ratio\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(data=df_eda, x='source', y='ttr')\n",
    "plt.title(\"Type-Token Ratio (TTR) by Source\")\n",
    "plt.ylabel(\"TTR\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split LLM data\n",
    "df_chatgpt = df_llm[df_llm['source'] == 'Chatgpt']\n",
    "df_deepseek = df_llm[df_llm['source'] == 'Deepseek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute word frequencies and normalize\n",
    "def top_word_freqs(texts, label, total_words=None, top_n=20):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        tokens = re.findall(r'\\b\\w+\\b', str(text))\n",
    "        words.extend(tokens)\n",
    "    counter = Counter(words)\n",
    "    if total_words is None:\n",
    "        total_words = sum(counter.values())\n",
    "    top_words = counter.most_common(top_n)\n",
    "    df = pd.DataFrame(top_words, columns=['word', 'count'])\n",
    "    df['frequency'] = df['count'] / total_words * 100\n",
    "    df['source'] = label\n",
    "    return df[['word', 'frequency', 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 20 frequency tables\n",
    "real_freqs = top_word_freqs(df_real['clean_no_stopwords'], 'Real')\n",
    "train_freqs = top_word_freqs(df_train['clean_no_stopwords'], 'Train')\n",
    "chatgpt_freqs = top_word_freqs(df_chatgpt['clean_no_stopwords'], 'ChatGPT')\n",
    "deepseek_freqs = top_word_freqs(df_deepseek['clean_no_stopwords'], 'DeepSeek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all\n",
    "df_words_long = pd.concat([real_freqs, chatgpt_freqs, deepseek_freqs, train_freqs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067600d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grouped bar plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(data=df_words_long, x='word', y='frequency', hue='source')\n",
    "plt.title(\"Top Shared Words by Relative Frequency (%) â€” Grouped Bar Plot\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e8596",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner joining data framers into one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1305279",
   "metadata": {},
   "source": [
    "### Defining preprocessing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5842e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremity Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31661c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # run all functions in here:\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
