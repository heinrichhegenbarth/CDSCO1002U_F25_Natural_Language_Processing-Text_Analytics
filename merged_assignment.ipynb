{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b689e9be",
   "metadata": {},
   "source": [
    "- As we have to hand in one file for data, one file for our analysis and one file for our text, I would suggst to merge the entirety of the analysis into this wb. \n",
    "- maybe we can have the data generation in a seperate file. \n",
    "\n",
    "- I would also suggest putting all the code into functions that we can comment out the fn calls to not have to run the entire code over and over again"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Imports & Configs:",
   "id": "a99feb2dcc02b174"
  },
  {
   "cell_type": "code",
   "id": "6c19efc5",
   "metadata": {},
   "source": [
    "# Standard library imports\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from typing import List, Set\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Gensim imports\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    adjusted_rand_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    f1_score,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    silhouette_score\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.manifold import trustworthiness\n",
    "\n",
    "# Transformers and datasets imports\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "# Other ML/DL imports\n",
    "import tensorflow_hub as hub\n",
    "from umap.umap_ import UMAP\n",
    "import hdbscan\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "e8fc49ee77f076d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "id": "2914fcec2c472a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Import Datasets:",
   "id": "9848d7b22a510f50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import Data Frames\n",
    "generated = pd.read_csv('0_data/statements.csv')\n",
    "parliament = pd.read_csv('0_data/final_labeled_dataset.csv')"
   ],
   "id": "49e7e71a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "generated.info()",
   "id": "af135910553806d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "parliament.info()",
   "id": "4106757ab6ccadd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "generated.statement.sample(5)",
   "id": "bee0388181fb98b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "parliament.translated_text.sample(5)",
   "id": "c830ed1da4157f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "generated.isna().sum()",
   "id": "f3661480ad641a85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "parliament.isna().sum()",
   "id": "12951166408420d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Preprocessing Class:",
   "id": "9ced19dba9551230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Preprocess:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    _stopwords: Set[str] = None\n",
    "    _lemmatizer: WordNetLemmatizer = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self._lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def rm_stopwords(self, text: str) -> str:\n",
    "        return ' '.join([word for word in text.split()\n",
    "                         if word not in self._stopwords])\n",
    "\n",
    "    def lemmatize_doc(self, tokens: List[str]) -> List[str]:\n",
    "        return [self._lemmatizer.lemmatize(word) for word in tokens\n",
    "                if word.isalpha() and word.lower() not in self._stopwords and len(word) > 2]\n",
    "\n",
    "    def trigrams(self, text: str) -> List[tuple]:\n",
    "        tokens = self.tokenize_doc(text)\n",
    "        return list(ngrams(tokens, 3))\n",
    "\n",
    "    @staticmethod\n",
    "    def basic_clean(text: str) -> str:\n",
    "        return re.sub(r'[^a-z\\s]', '', str(text).lower())\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_doc(text: str) -> List[str]:\n",
    "        return word_tokenize(text.lower())"
   ],
   "id": "ac2f9f25b1666094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "preprocessor = Preprocess()",
   "id": "15b4ac25097ba2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Descriptive Analytics",
   "id": "4edf9062"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "generated_da = generated.copy()\n",
    "parliament_da = parliament.copy()"
   ],
   "id": "ac2601785447ef09",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "506f19ad",
   "metadata": {},
   "source": [
    "parliament_da['clean_with_stopwords'] = parliament_da['translated_text'].apply(preprocessor.basic_clean)\n",
    "generated_da['clean_with_stopwords'] = generated_da['statement'].apply(preprocessor.basic_clean)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a818ed6",
   "metadata": {},
   "source": [
    "# Length + Style Metrics (with stopwords)\n",
    "parliament_da['char_count'] = parliament_da['clean_with_stopwords'].str.len()\n",
    "parliament_da['word_count'] = parliament_da['clean_with_stopwords'].str.split().str.len()\n",
    "parliament_da['source'] = 'Real'\n",
    "\n",
    "generated_da['char_count'] = generated_da['clean_with_stopwords'].str.len()\n",
    "generated_da['word_count'] = generated_da['clean_with_stopwords'].str.split().str.len()\n",
    "generated_da['source'] = generated_da['provider'].str.capitalize()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36bd75fc",
   "metadata": {},
   "source": [
    "parliament_da['clean_no_stopwords'] = parliament_da['clean_with_stopwords'].apply(preprocessor.rm_stopwords)\n",
    "generated_da['clean_no_stopwords'] = generated_da['clean_with_stopwords'].apply(preprocessor.rm_stopwords)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_word_counts(texts):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "        words.extend(tokens)\n",
    "    return Counter(words)"
   ],
   "id": "90eda5eea2d4332",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a6e51d9",
   "metadata": {},
   "source": [
    "# Word frequency analysis\n",
    "real_words = get_word_counts(parliament_da['clean_no_stopwords'])\n",
    "llm_words = get_word_counts(generated_da['clean_no_stopwords'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8519b801",
   "metadata": {},
   "source": [
    "# Top 20\n",
    "real_top20 = pd.DataFrame(real_words.most_common(20), columns=['word', 'real_count'])\n",
    "llm_top20 = pd.DataFrame(llm_words.most_common(20), columns=['word', 'llm_count'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05cd681f",
   "metadata": {},
   "source": [
    "# Merge top word frequencies\n",
    "word_counts = pd.merge(real_top20, llm_top20, on='word', how='outer').fillna(0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine for analysis\n",
    "df_da = pd.concat([\n",
    "    parliament_da[['char_count', 'word_count', 'source']],\n",
    "    generated_da[['char_count', 'word_count', 'source']]\n",
    "])"
   ],
   "id": "f4b349a4979ebc66",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "951c610b",
   "metadata": {},
   "source": [
    "# Histogram: Character Count\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(data=df_da, x='char_count', hue='source', bins=40, element='step', stat='count', common_norm=False)\n",
    "plt.title(\"Character Count Distribution by Source\")\n",
    "plt.xlabel(\"Character Count\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# compute word frequencies and normalize\n",
    "def top_word_freqs(texts, label, total_words=None, top_n=20):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        tokens = re.findall(r'\\b\\w+\\b', str(text))\n",
    "        words.extend(tokens)\n",
    "    counter = Counter(words)\n",
    "    if total_words is None:\n",
    "        total_words = sum(counter.values())\n",
    "    top_words = counter.most_common(top_n)\n",
    "    df = pd.DataFrame(top_words, columns=['word', 'count'])\n",
    "    df['frequency'] = df['count'] / total_words * 100\n",
    "    df['source'] = label\n",
    "    return df[['word', 'frequency', 'source']]"
   ],
   "id": "ab4b42a6a5367451",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split LLM data\n",
    "df_chatgpt = generated_da[generated_da['source'] == 'Chatgpt']\n",
    "df_deepseek = generated_da[generated_da['source'] == 'Deepseek']"
   ],
   "id": "f1389e1e0cc4dc8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate top 20 frequency tables\n",
    "real_freqs = top_word_freqs(parliament_da['clean_no_stopwords'], 'Real')\n",
    "chatgpt_freqs = top_word_freqs(df_chatgpt['clean_no_stopwords'], 'ChatGPT')\n",
    "deepseek_freqs = top_word_freqs(df_deepseek['clean_no_stopwords'], 'DeepSeek')"
   ],
   "id": "1487f688f74970f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine all\n",
    "df_words_long = pd.concat([real_freqs, chatgpt_freqs, deepseek_freqs], ignore_index=True)"
   ],
   "id": "ca1d742d6fdc5b1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot grouped bar plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(data=df_words_long, x='word', y='frequency', hue='source')\n",
    "plt.title(\"Top Shared Words by Relative Frequency (%) â€” Grouped Bar Plot\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "37afdf05560b64be",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa8af500",
   "metadata": {},
   "source": [
    "# Boxplot: Type-Token Ratio\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(data=df_da, x='source', y='ttr')\n",
    "plt.title(\"Type-Token Ratio (TTR) by Source\")\n",
    "plt.ylabel(\"TTR\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4ea5d84ba54b1eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2a5842e",
   "metadata": {},
   "source": "## Analysis"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Topic modeling",
   "id": "9cdce88466c2dbb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SEED = 42",
   "id": "fa539ecd319d4cad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tune_umap_parameters(embeddings, n_calls: int=50, verbose: bool=False):\n",
    "\n",
    "    space = [\n",
    "        Integer(10, 50, name='n_neighbors'),\n",
    "        Real(0.0, 0.3, name='min_dist'),\n",
    "        Categorical(['euclidean'], name='metric')\n",
    "    ]\n",
    "\n",
    "    def objective(params, embeddings, n_components=2):\n",
    "        n_neighbors, min_dist, metric = params\n",
    "\n",
    "        reducer = UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            metric=metric,\n",
    "            n_components=n_components,\n",
    "            random_state=SEED\n",
    "        )\n",
    "\n",
    "        embedding = reducer.fit_transform(embeddings)\n",
    "\n",
    "        trust_score = trustworthiness(\n",
    "            embeddings,\n",
    "            embedding,\n",
    "            n_neighbors=min(20, len(embeddings) - 1)\n",
    "        )\n",
    "\n",
    "        return -trust_score\n",
    "\n",
    "    result = gp_minimize(\n",
    "        lambda params: objective(params, embeddings),\n",
    "        space,\n",
    "        n_calls=n_calls,\n",
    "        random_state=SEED,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    best_params = {\n",
    "        'n_neighbors': result.x[0],\n",
    "        'min_dist': result.x[1],\n",
    "        'metric': result.x[2]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBest parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest score: {-result.fun:.4f}\")\n",
    "\n",
    "    best_reducer = UMAP(\n",
    "        **best_params,\n",
    "        n_components=2,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    return best_params, best_reducer"
   ],
   "id": "e37a26dd7289ca68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tune_hdbscan_parameters(embeddings,  n_calls: int=50, verbose: bool=False):\n",
    "\n",
    "    space = [\n",
    "        Integer(3, 15, name='min_cluster_size'),\n",
    "        Integer(3, 10, name='min_samples'),\n",
    "        Real(0.0, 0.5, name='cluster_selection_epsilon'),\n",
    "        Categorical(['euclidean'], name='metric')\n",
    "    ]\n",
    "\n",
    "    def objective(params, embeddings, n_runs=5):\n",
    "        min_cluster_size, min_samples, cluster_selection_epsilon, metric = params\n",
    "\n",
    "        cluster_results = []\n",
    "        silhouette_scores = []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            clusterer = hdbscan.HDBSCAN(\n",
    "                min_cluster_size=min_cluster_size,\n",
    "                min_samples=min_samples,\n",
    "                cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "                metric=metric\n",
    "            )\n",
    "\n",
    "            labels = clusterer.fit_predict(embeddings)\n",
    "            cluster_results.append(labels)\n",
    "\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            if n_clusters > 1:\n",
    "                mask = labels != -1\n",
    "                if np.sum(mask) > 1:\n",
    "                    sil_score = silhouette_score(embeddings[mask], labels[mask])\n",
    "                    silhouette_scores.append(sil_score)\n",
    "\n",
    "        stability_scores = []\n",
    "        for i in range(len(cluster_results)):\n",
    "            for j in range(i + 1, len(cluster_results)):\n",
    "                ari = adjusted_rand_score(cluster_results[i], cluster_results[j])\n",
    "                stability_scores.append(ari)\n",
    "\n",
    "        mean_stability = np.mean(stability_scores) if stability_scores else 0\n",
    "        mean_silhouette = np.mean(silhouette_scores) if silhouette_scores else 0\n",
    "\n",
    "        noise_ratio = np.sum(cluster_results[-1] == -1) / len(cluster_results[-1])\n",
    "\n",
    "        composite_score = (0.4 * mean_stability +\n",
    "                          0.4 * mean_silhouette -\n",
    "                          0.2 * noise_ratio)\n",
    "\n",
    "        return -composite_score\n",
    "\n",
    "    result = gp_minimize(\n",
    "        lambda params: objective(params, embeddings),\n",
    "        space,\n",
    "        n_calls=n_calls,\n",
    "        random_state=SEED,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    best_params = {\n",
    "        'min_cluster_size': result.x[0],\n",
    "        'min_samples': result.x[1],\n",
    "        'cluster_selection_epsilon': result.x[2],\n",
    "        'metric': result.x[3]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBest HDBSCAN parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest score: {-result.fun:.4f}\")\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(**best_params)\n",
    "    labels = clusterer.fit_predict(embeddings)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    noise_points = sum(1 for label in labels if label == -1)\n",
    "\n",
    "    print(f\"\\nNumber of clusters: {n_clusters}\")\n",
    "    print(f\"Number of noise points: {noise_points} ({noise_points/len(labels):.2%})\")\n",
    "\n",
    "    return best_params, clusterer"
   ],
   "id": "b43753dadc92cb78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_closest_words(topic_vector, word_vectors, n=10):\n",
    "    similarities = cosine_similarity([topic_vector], word_vectors)[0]\n",
    "    return np.argsort(similarities)[-n:][::-1]"
   ],
   "id": "69bb2f1b31bc8b2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tm_cleaning(doc):\n",
    "    doc = preprocessor.basic_clean(doc)\n",
    "    tokens = preprocessor.tokenize_doc(doc)\n",
    "    tokens = preprocessor.lemmatize_doc(tokens)\n",
    "    return tokens"
   ],
   "id": "f7b13c187991c369",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_chatgpt = generated[generated.provider == 'chatgpt']\n",
    "df_deepseek = generated[generated.provider == 'deepseek']"
   ],
   "id": "69aac03b50bcfb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "docs_chatgpt = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_chatgpt.statement.apply(tm_cleaning).tolist())]\n",
    "docs_deepseek = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_deepseek.statement.apply(tm_cleaning).tolist())]"
   ],
   "id": "1559c5953063997c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "texts_chatgpt = [' '.join(doc.words) if hasattr(doc, 'words') else doc for doc in docs_chatgpt]\n",
    "texts_deepseek = [' '.join(doc.words) if hasattr(doc, 'words') else doc for doc in docs_deepseek]"
   ],
   "id": "b5eb87db10397a1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "scaler = StandardScaler()\n",
    "embeddings_chatgpt = scaler.fit_transform(embed(texts_chatgpt).numpy())\n",
    "embeddings_deepseek = scaler.fit_transform(embed(texts_deepseek).numpy())"
   ],
   "id": "b6aad11c7d24a9e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_umap_params_chatgpt, reducer_chatgpt = tune_umap_parameters(embeddings_chatgpt)",
   "id": "23bab445a3489579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_umap_params_deepseek, reducer_deepseek = tune_umap_parameters(embeddings_deepseek)",
   "id": "95aad10e205ff94a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_hdbscan_params_chatgpt, clusterer_chatgpt = tune_hdbscan_parameters(embeddings_chatgpt)",
   "id": "c35a0143c2754942",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_hdbscan_params_deepseek, clusterer_deepseek = tune_hdbscan_parameters(embeddings_deepseek)",
   "id": "228733594a791ca2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "umap_embeddings_chatgpt = reducer_chatgpt.fit_transform(embeddings_chatgpt)\n",
    "umap_embeddings_deepseek = reducer_deepseek.fit_transform(embeddings_deepseek)"
   ],
   "id": "d0b2bfde05229314",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_labels_chatgpt = clusterer_chatgpt.fit_predict(umap_embeddings_chatgpt)\n",
    "cluster_labels_deepseek = clusterer_deepseek.fit_predict(umap_embeddings_deepseek)"
   ],
   "id": "7e8d96b52e38b2fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "umap_hdbscan_results = {\n",
    "    'ChatGPT': (umap_embeddings_chatgpt, cluster_labels_chatgpt),\n",
    "    'DeepSeek': (umap_embeddings_deepseek, cluster_labels_deepseek)\n",
    "}"
   ],
   "id": "d48f6843a012f59f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "fig.suptitle('Document Clusters Comparison', fontsize=16, y=1.05)\n",
    "\n",
    "for idx, (name, res) in enumerate(umap_hdbscan_results.items()):\n",
    "    scatter = axes[idx].scatter(res[0][:, 0],\n",
    "                               res[0][:, 1],\n",
    "                               c=res[1],\n",
    "                               cmap='Spectral',\n",
    "                               alpha=0.6)\n",
    "    fig.colorbar(scatter, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{name}')\n",
    "    axes[idx].set_xlabel('UMAP 1')\n",
    "    axes[idx].set_ylabel('UMAP 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "85f32a8d191bd918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_clusters_chatgpt = len(np.unique(cluster_labels_chatgpt[cluster_labels_chatgpt != -1]))\n",
    "\n",
    "topic_vectors = []\n",
    "\n",
    "for i in range(n_clusters_chatgpt):\n",
    "    cluster_docs = embeddings_chatgpt[cluster_labels_chatgpt == i]\n",
    "    centroid = np.mean(cluster_docs, axis=0)\n",
    "    topic_vectors.append(centroid)\n",
    "\n",
    "topic_vectors_chatgpt = np.array(topic_vectors)"
   ],
   "id": "29a24917c082921b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_clusters_deepseek = len(np.unique(cluster_labels_deepseek[cluster_labels_deepseek != -1]))\n",
    "\n",
    "topic_vectors = []\n",
    "\n",
    "for i in range(n_clusters_deepseek):\n",
    "    cluster_docs = embeddings_deepseek[cluster_labels_deepseek == i]\n",
    "    centroid = np.mean(cluster_docs, axis=0)\n",
    "    topic_vectors.append(centroid)\n",
    "\n",
    "topic_vectors_deepseek = np.array(topic_vectors)"
   ],
   "id": "daad045f916c1a96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Results:",
   "id": "b3e6bb3db26d0488"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def top_words(cluster_labels,\n",
    "              texts,\n",
    "              topic_vectors,\n",
    "              embeddings,\n",
    "              n_words=10):\n",
    "\n",
    "    n_clusters = len(np.unique(cluster_labels[cluster_labels != -1]))\n",
    "\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    doc_term_matrix = count_vectorizer.fit_transform(texts)\n",
    "    vocabulary = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "    c_tf_idf_matrix = np.zeros((n_clusters, len(vocabulary)))\n",
    "\n",
    "    for cluster_id in range(n_clusters):\n",
    "\n",
    "        cluster_docs = doc_term_matrix[cluster_labels == cluster_id]\n",
    "\n",
    "        if cluster_docs.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        cluster_tf = np.array(cluster_docs.sum(axis=0).flatten())[0]\n",
    "        total_docs = len(texts)\n",
    "        cluster_size = cluster_docs.shape[0]\n",
    "\n",
    "        tf_idf = cluster_tf * np.log1p(total_docs / (cluster_size + 1))\n",
    "        c_tf_idf_matrix[cluster_id] = tf_idf\n",
    "\n",
    "    all_top_words = []\n",
    "\n",
    "    for topic_idx in range(c_tf_idf_matrix.shape[0]):\n",
    "        top_n_idx = c_tf_idf_matrix[topic_idx].argsort()[-n_words:][::-1]\n",
    "        top_words = [vocabulary[idx] for idx in top_n_idx]\n",
    "        all_top_words.append(top_words)\n",
    "\n",
    "        print(f\"\\nTopic {topic_idx + 1} Top Words:\")\n",
    "        print(\", \".join(top_words))\n",
    "\n",
    "    return [item for sublist in all_top_words for item in sublist]"
   ],
   "id": "796aee010833b20a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_words_chatgpt = top_words(cluster_labels_chatgpt,\n",
    "                              texts_chatgpt,\n",
    "                              topic_vectors_chatgpt,\n",
    "                              embeddings_chatgpt,\n",
    "                              n_words=10)"
   ],
   "id": "806a8b57d8285ba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_words_deepseek = top_words(cluster_labels_deepseek,\n",
    "                               texts_deepseek,\n",
    "                               topic_vectors_deepseek,\n",
    "                               embeddings_deepseek,\n",
    "                               n_words=10)"
   ],
   "id": "e088c06c187ef73e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_words_chatgpt = set(top_words_chatgpt) - set(top_words_deepseek)\n",
    "print(f'Unique words in ChatGPT: {unique_words_chatgpt}')\n",
    "\n",
    "unique_words_deepseek = set(top_words_deepseek) - set(top_words_chatgpt)\n",
    "print(f'Unique words deepseek: {unique_words_deepseek}')\n",
    "\n",
    "common_words = set(top_words_deepseek) & set(top_words_chatgpt)\n",
    "print(f'Common words: {common_words}')"
   ],
   "id": "72e7349b9584b53f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_topic_modeling(cluster_labels, embeddings, texts, topic_vectors, model_results=None):\n",
    "    valid_mask = cluster_labels != -1\n",
    "    clustering_metrics = {}\n",
    "\n",
    "    if np.sum(valid_mask) > 1:\n",
    "        clustering_metrics = {\n",
    "            'silhouette_score': silhouette_score(\n",
    "                embeddings[valid_mask],\n",
    "                cluster_labels[valid_mask]\n",
    "            ),\n",
    "            'calinski_harabasz_score': calinski_harabasz_score(\n",
    "                embeddings[valid_mask],\n",
    "                cluster_labels[valid_mask]\n",
    "            ),\n",
    "            'davies_bouldin_score': davies_bouldin_score(\n",
    "                embeddings[valid_mask],\n",
    "                cluster_labels[valid_mask]\n",
    "            )\n",
    "        }\n",
    "\n",
    "    tokenized_texts = [text.split() for text in texts]\n",
    "    dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "    topic_words = []\n",
    "    for i in range(len(topic_vectors)):\n",
    "        topic_mask = cluster_labels == i\n",
    "        topic_texts = [text for text, mask in zip(texts, topic_mask) if mask]\n",
    "        words = ' '.join(topic_texts).split()\n",
    "        word_freq = {}\n",
    "        for word in words:\n",
    "            word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        topic_words.append([word for word, freq in sorted_words[:10]])  # top 10 words\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "\n",
    "    coherence_metrics = {\n",
    "        'c_v_coherence': coherence_model.get_coherence()\n",
    "    }\n",
    "\n",
    "    topic_similarities = cosine_similarity(topic_vectors)\n",
    "    np.fill_diagonal(topic_similarities, 0)\n",
    "    distinctiveness_metrics = {\n",
    "        'mean_similarity': np.mean(topic_similarities),\n",
    "        'max_similarity': np.max(topic_similarities)\n",
    "    }\n",
    "\n",
    "    topic_sizes = np.bincount(cluster_labels[cluster_labels != -1])\n",
    "    size_metrics = {\n",
    "        'size_std': np.std(topic_sizes),\n",
    "        'size_range': np.ptp(topic_sizes),\n",
    "        'noise_ratio': np.sum(cluster_labels == -1) / len(cluster_labels)\n",
    "    }\n",
    "\n",
    "    evaluation_results = {\n",
    "        'clustering_metrics': clustering_metrics,\n",
    "        'coherence': coherence_metrics,\n",
    "        'distinctiveness': distinctiveness_metrics,\n",
    "        'size_metrics': size_metrics\n",
    "    }\n",
    "\n",
    "    print(\"\\nEvaluation Results\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for category, metrics in evaluation_results.items():\n",
    "        print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "    return evaluation_results"
   ],
   "id": "47c23e944b92d395",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_res_chatgpt = evaluate_topic_modeling(cluster_labels_chatgpt,\n",
    "                                            embeddings_chatgpt,\n",
    "                                            texts_chatgpt,\n",
    "                                            topic_vectors_chatgpt,\n",
    "                                            model_results=umap_hdbscan_results)"
   ],
   "id": "83a121039dbe3708",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eval_res_deepseek = evaluate_topic_modeling(cluster_labels_deepseek,\n",
    "                                            embeddings_deepseek,\n",
    "                                            texts_deepseek,\n",
    "                                            topic_vectors_deepseek,\n",
    "                                            model_results=umap_hdbscan_results)"
   ],
   "id": "3a982a773608c171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sentiment Analysis",
   "id": "bb2b291f5d6aa0bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nltk.download('vader_lexicon')",
   "id": "2bf6b8da934c2a5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']"
   ],
   "id": "1f526259b909bec5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parliament['sentiment'] = parliament['translated_text'].apply(get_sentiment)\n",
    "generated['sentiment'] = generated['completion'].apply(get_sentiment)"
   ],
   "id": "6c45008254b56af2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Results:",
   "id": "25bf48b4b0b08d8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_descriptive_printout(sentiment):\n",
    "    return [sentiment.mean(), sentiment.std(), sentiment.min(), sentiment.max(), sentiment.count()]\n",
    "\n",
    "sentiment_original = get_descriptive_printout(parliament['sentiment'])\n",
    "is_openai = generated['client'] == 'chatgpt'\n",
    "is_deepseek = generated['client'] == 'deepseek'\n",
    "sentiment_openai_deepseek = get_descriptive_printout(generated[is_deepseek]['sentiment'])\n",
    "sentiment_openai_chatgpt = get_descriptive_printout(generated[is_openai]['sentiment'])"
   ],
   "id": "8c18ae029e66af17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create table\n",
    "sentiment_table = PrettyTable()\n",
    "sentiment_table.field_names = ['Source', 'Mean', 'Std Dev', 'Min', 'Max', 'Count']\n",
    "sentiment_table.add_row(['Original', *sentiment_original])\n",
    "sentiment_table.add_row(['ChatGPT', *sentiment_openai_chatgpt])\n",
    "sentiment_table.add_row(['DeepSeek', *sentiment_openai_deepseek])"
   ],
   "id": "f2cbd05796059bbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print table\n",
    "print('Sentiment Analysis (Vader) Results:')\n",
    "print('> uncleaned data')\n",
    "print(sentiment_table)"
   ],
   "id": "136b6fc3d8af60d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extremity Regression",
   "id": "f8f8458be56eaaaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Ridge Regression:",
   "id": "17b7756928fcb574"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def reg_preprocess_text(dataset):\n",
    "    return dataset.map(\n",
    "        lambda x: ' '.join(\n",
    "            preprocessor.lemmatize_doc(\n",
    "                preprocessor.tokenize_doc(\n",
    "                    preprocessor.rm_stopwords(\n",
    "                        preprocessor.basic_clean(x)  # Remove ['translated_text'] access\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "X = parliament['translated_text']\n",
    "X = reg_preprocess_text(X)"
   ],
   "id": "8485f127e80590c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y = parliament['label']",
   "id": "749857d92889254b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "6a469ad71d418e7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ],
   "id": "7f4b27c6cb72a87e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train Ridge regression model\n",
    "model = Ridge()\n",
    "model.fit(X_train_vec, y_train)"
   ],
   "id": "a3222a9810b3f06a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_test_vec)"
   ],
   "id": "de0992a01f80f608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)"
   ],
   "id": "fb623a485ff305c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.plot([-1, 1], [-1, 1], '--', color='gray')\n",
    "plt.title(\"Predicted vs. Actual Extremity\")\n",
    "plt.xlabel(\"Actual Extremity\")\n",
    "plt.ylabel(\"Predicted Extremity\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b65a90ce04603345",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### RoBERTa:",
   "id": "2150e0336eaed957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ],
   "id": "86d5b9a881748e7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "df = parliament[parliament[\"translated_text\"].notna() & parliament[\"label\"].notna()]"
   ],
   "id": "f17a47cf77564475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ],
   "id": "1e203fe2e6de8473",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare datasets\n",
    "train_df = train_df.rename(columns={\"label\": \"labels\"})\n",
    "test_df = test_df.rename(columns={\"label\": \"labels\"})\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"translated_text\", \"labels\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"translated_text\", \"labels\"]])"
   ],
   "id": "85a145f9ecc37c86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use RoBERTa for regression\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ],
   "id": "824ea6a7068d185d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"translated_text\"], padding=\"max_length\", truncation=True)"
   ],
   "id": "6139fb00a1b0e73b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ],
   "id": "43d0a6507abd7edc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load model for regression\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=1,\n",
    "    problem_type=\"regression\"\n",
    ")\n",
    "model.config.hidden_dropout_prob = 0.3  # reduce overfitting"
   ],
   "id": "b821725637da752d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.squeeze()\n",
    "    return {\n",
    "        \"mse\": mean_squared_error(labels, preds),\n",
    "        \"r2\": r2_score(labels, preds)\n",
    "    }"
   ],
   "id": "388eee1a053c5e19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./spectrum_bert_results\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=12,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./spectrum_logs\"\n",
    ")"
   ],
   "id": "66366f26362583ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "6cd7867f99bb46fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train\n",
    "trainer.train()"
   ],
   "id": "e15c166a9b532ee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# evaluate\n",
    "trainer.evaluate()"
   ],
   "id": "bd9094807a5d563",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"roberta_best\")\n",
    "tokenizer.save_pretrained(\"roberta_best\")"
   ],
   "id": "73412eb9c2bba82f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "statements = generated[\"statement\"].tolist()\n",
    "\n",
    "model_path = \"roberta_best\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "extremity_scores = []\n",
    "for text in statements:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        score = outputs.logits.item()\n",
    "        extremity_scores.append(score)\n",
    "\n",
    "generated[\"extremity_score\"] = extremity_scores"
   ],
   "id": "3496fdf3d9dfc8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(data=generated, x=\"extremity_score\", hue=\"provider\", fill=True, common_norm=False, alpha=0.5)\n",
    "plt.axvline(0, linestyle=\"--\", color=\"gray\")\n",
    "plt.title(\"Distribution of Predicted Extremity Scores by Provider\")\n",
    "plt.xlabel(\"Extremity Score (-1 = Left, +1 = Right)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6a239791a0cab825",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.boxplot(data=generated, x=\"provider\", y=\"extremity_score\")\n",
    "plt.title(\"Extremity Score Distribution per LLM\")\n",
    "plt.axhline(0, linestyle=\"--\", color=\"gray\")\n",
    "plt.ylabel(\"Predicted Extremity\")\n",
    "plt.show()"
   ],
   "id": "e56b9b26c27d1451",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(generated.groupby(\"provider\")[\"extremity_score\"].agg([\"mean\", \"std\", \"min\", \"max\", \"median\"]))",
   "id": "c4be249b3713e2b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chatgpt_df = generated[generated[\"provider\"].str.lower() == \"chatgpt\"]\n",
    "num_left_leaning = (chatgpt_df[\"extremity_score\"] < 0).sum()\n",
    "total = len(chatgpt_df)\n",
    "print(f\"ChatGPT statements leaning left (< 0): {num_left_leaning} out of {total} ({(num_left_leaning/total)*100:.2f}%)\")"
   ],
   "id": "36f67b0ebf135e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a23febb39a64698e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
